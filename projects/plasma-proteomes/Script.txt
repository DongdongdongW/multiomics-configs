import os
import pandas as pd
import webbrowser
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.options import Options
import time
import re

folder_path = r'C:\Users\HP zBook 15v\Desktop\datasets'
file_list = os.listdir(folder_path)

df = pd.DataFrame(columns=['PXD', 'Pubmed', 'sdrf URL', 'msstats URL', 'method', 'Samples', 'run'])
driver = webdriver.Chrome()

cookies = 0
row_index = 0

def pubmed():
    driver.get("https://pubmed.ncbi.nlm.nih.gov/")
    pubmed = driver.find_element(By.XPATH, "/html/body/div[2]/main/div[1]/div/form/div[1]/div[1]/div/span/input")
    pubmed.send_keys(paper_name)
    try:
        doi_search = driver.find_element(By.XPATH, "/html/body/div[5]/main/header/div[1]/ul/li[2]/span/a")
        pubmed_value = doi_search.text
    except:
        try:
            pubmed_search = driver.find_element(By.XPATH, "/html/body/div[2]/main/div[1]/div/form/div[1]/div[1]/div/span/input")
            pubmed_search.send_keys(Keys.RETURN)
            try:
                pubmed_articulo = driver.find_element(By.XPATH, "/html/body/main/div[9]/div[2]/section[2]/div[1]/div/article[1]/div[2]/div[1]/a")
                pubmed_articulo.click()
                time.sleep(3)
                try:
                    doi_search = driver.find_element(By.XPATH, "/html/body/div[5]/main/header/div[1]/ul/li[2]/span/a")
                except:
                    doi_search = driver.find_element(By.XPATH, "/html/body/div[5]/main/header/div[1]/ul/li[3]/span/a")
                
                pubmed_value = doi_search.text
            except:
                pubmed_articulo = driver.find_element(By.XPATH, "/html/body/main/div[9]/div[2]/section/div[1]/div/article[1]/div[2]/div[1]/a")
                pubmed_articulo.click()
                time.sleep(3)
                try:
                    doi_search = driver.find_element(By.XPATH, "/html/body/div[5]/main/header/div[1]/ul/li[2]/span/a")
                except:
                    doi_search = driver.find_element(By.XPATH, "/html/body/div[5]/main/header/div[1]/ul/li[3]/span/a")
                
                pubmed_value = doi_search.text

        except:
            pubmed_value = "NOT FOUND"

    df.loc[row_index, 'Pubmed'] = pubmed_value

def absolute():
    number = 0
    file_found = False
    max_iterations = 6
    iteration = 0
    msstats_url = ""
    sdrf_url = ""

    while not file_found and iteration < max_iterations:
        try:
            if iteration == 0:
                url_options = [
                    f"http://ftp.pride.ebi.ac.uk/pub/databases/pride/resources/proteomes/absolute-expression/{PXD_code}/proteomicslfq/",
                    f"http://ftp.pride.ebi.ac.uk/pub/databases/pride/resources/proteomes/absolute-expression/{PXD_code}/msstatsconverter/",
                    f"http://ftp.pride.ebi.ac.uk/pub/databases/pride/resources/proteomes/absolute-expression/{PXD_code}/diannconverter/"
                ]
            else:
                url_options = [
                    f"http://ftp.pride.ebi.ac.uk/pub/databases/pride/resources/proteomes/absolute-expression/{PXD_code}.{number}/proteomicslfq/",
                    f"http://ftp.pride.ebi.ac.uk/pub/databases/pride/resources/proteomes/absolute-expression/{PXD_code}.{number}/msstatsconverter/",
                    f"http://ftp.pride.ebi.ac.uk/pub/databases/pride/resources/proteomes/absolute-expression/{PXD_code}.{number}/diannconverter/"
                ]

            for url_msstats in url_options:
                driver.get(url_msstats)
                time.sleep(1)

                file_elements = driver.find_elements(By.TAG_NAME, "a")
                for file_element in file_elements:
                    if ".sdrf_openms_design_msstats_in.csv" in file_element.text:
                        msstats_absolute_file = file_element.text
                        msstats_absolute_split = msstats_absolute_file.split(".", 1)[0]
                        if full_name == msstats_absolute_split:
                            msstats_url = driver.current_url
                            sdrf_url = url_msstats.replace("msstatsconverter/", "pipeline_info/")
                            driver.get(url_msstats)
                            time.sleep(5)
                            file_found = True
                            break
                
                if file_found:
                    break
            iteration += 1
            

        except Exception as e:
            print("An error occurred:", str(e))

        number += 1

    if not file_found:
        print(file_name+"File not found within the maximum number of iterations.")

    df.loc[row_index, 'msstats URL'] = msstats_url
    df.loc[row_index, 'sdrf URL'] = sdrf_url

def sdrf_run():
    for file_name in file_list:

        if 'source name' in dataframe.columns and any(item in dataframe.iloc[0]['source name'] for item in ['TMT']):
            df.loc[row_index, 'method'] = "TMT"
        elif 'comment[label]' in dataframe.columns and any(item in str(dataframe.iloc[0]['comment[label]']) for item in ['TMT']):
            df.loc[row_index, 'method'] = "TMT"

        elif 'source name' in dataframe.columns and any(item in dataframe.iloc[0]['source name'] for item in ['iTRAQ']):
            df.loc[row_index, 'method'] = "iTRAQ"
        elif 'comment[label]' in dataframe.columns and any(item in str(dataframe.iloc[0]['comment[label]']) for item in ['iTRAQ']):
            df.loc[row_index, 'method'] = "iTRAQ"    

        elif 'source name' in dataframe.columns and any(item in dataframe.iloc[0]['source name'] for item in ['DIA']):
            df.loc[row_index, 'method'] = "DIA"
        elif 'comment[proteomics data acquisition method]' in dataframe.columns and any(item in str(dataframe.iloc[0]['comment[proteomics data acquisition method]']) for item in ['Data-Independent Acquisition']):
            df.loc[row_index, 'method'] = "DIA"

        elif 'source name' in dataframe.columns and any(item in dataframe.iloc[0]['source name'] for item in ['DDA']):
            df.loc[row_index, 'method'] = "DDA"
        elif 'comment[proteomics data acquisition method]' in dataframe.columns and any(item in str(dataframe.iloc[0]['comment[label]']) for item in ['DDA']):
            df.loc[row_index, 'method'] = "DDA"
        else:
            df.loc[row_index, 'method'] = "DIA (not sure)"

    
    sample = [int(re.search(r'Sample-(\d+)', item).group(1)) if re.search(r'Sample-(\d+)', item) else 0 for item in dataframe.iloc[:, 0]]
    largest_sample = max(sample)
    df.loc[row_index, 'Samples'] = largest_sample

    try:
        run = [int(re.search(r'(\d+)', item).group()) for item in dataframe['assay name']]
        run = dataframe['assay name'].nunique()
        df.loc[row_index, 'run'] = run
    except KeyError:
        df.loc[row_index, 'run'] = "error"


for file_name in file_list:
    file_path = os.path.join(folder_path, file_name)
    dataframe = pd.read_csv(file_path, sep='\t')

    base_name = os.path.splitext(file_name)[0]
    full_name = base_name.split('.')[0]
    
    if '-' in base_name:
        first_part = base_name.split('-')[0]
    else:
        first_part = base_name.split('.')[0]
    
    df.loc[row_index, 'PXD'] = full_name

    PXD_code = first_part
    if "PXD" in first_part:
        pride_url = "https://www.ebi.ac.uk/pride/archive?keyword=" + PXD_code.lower()
        driver.get(pride_url)
        time.sleep(2)
        if cookies == 0:
            cookies = driver.find_element(By.XPATH, "/html/body/div[2]/div/div[2]/a")
            cookies.click()
            cookies = 1
        try:
            boton_pride = driver.find_element(By.XPATH, "/html/body/div[1]/div[2]/div[2]/div[2]/div/div[2]/div[1]/div/div/a/span/span")
            boton_pride.click()
            time.sleep(2)
            doi_search = driver.find_element(By.XPATH, "/html/body/div[1]/div[2]/div[2]/div[2]/div[1]/div/div[2]/div[2]/div/div/p/a[1]")
            pubmed_value = doi_search.text
            df.loc[row_index, 'Pubmed'] = pubmed_value

        except:
            try:
                paper = driver.find_element(By.XPATH, "/html/body/div[1]/div[2]/div[2]/div[2]/div[1]/div/div[1]/div[2]/div[1]/p")
                paper_name = paper.text
                pubmed()
            except:
                pubmed_value = "NOT FOUND"
                df.loc[row_index, 'Pubmed'] = pubmed_value

    else:
        driver.get("https://massive.ucsd.edu/ProteoSAFe/static/massive.jsp")
        massive_search = driver.find_element(By.XPATH, "/html/body/div/div[2]/div[2]/div[2]/table/tbody/tr[1]/td[2]/input")
        massive_search.send_keys(first_part)
        massive_button = driver.find_element(By.XPATH, "/html/body/div/div[2]/div[2]/div[2]/table/tbody/tr[1]/td[2]/button")
        massive_button.click()
        time.sleep(2)
        paper = driver.find_element(By.XPATH, "/html/body/div[2]/div[1]/div[1]/h2")
        paper_name = paper.text
        pubmed()

    absolute()
    sdrf_run()

    row_index += 1
df
